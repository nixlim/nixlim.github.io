<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions | Foundry of Zero</title><meta name=description content="AI agents will build whatever you ask for. The problem is that 'whatever you ask for' and 'what you actually wanted' are different things. Taskify exists to close that gap."><meta property="og:title" content="Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions"><meta property="og:description" content="AI agents will build whatever you ask for. The problem is that 'whatever you ask for' and 'what you actually wanted' are different things. Taskify exists to close that gap."><meta property="og:url" content="https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/"><meta property="og:site_name" content="Foundry of Zero"><meta property="og:type" content="article"><meta property="og:image" content="https://foundryofzero.ai/images/og-default.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions"><meta name=twitter:description content="AI agents will build whatever you ask for. The problem is that 'whatever you ask for' and 'what you actually wanted' are different things. Taskify exists to close that gap."><meta name=twitter:image content="https://foundryofzero.ai/images/og-default.png"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;700&display=swap" rel=stylesheet><link rel=stylesheet href=/css/main.css><link rel=icon type=image/svg+xml href=/favicon.svg></head><body><nav class=site-nav role=navigation aria-label="Main navigation"><div class=nav-container><a href=/ class=nav-logo aria-label=Home>FoZ</a><ul class=nav-links><li><a href=/projects/>Projects</a></li><li><a href=/blog/>Blog</a></li><li><a href=/about/>About</a></li><li><a href=https://github.com/nixlim target=_blank rel="noopener noreferrer" class=nav-github aria-label=GitHub><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg></a></li></ul><button class=nav-hamburger aria-label="Toggle menu" aria-expanded=false aria-controls=mobile-menu>
<span class=hamburger-line></span>
<span class=hamburger-line></span>
<span class=hamburger-line></span></button></div><div class=mobile-menu id=mobile-menu aria-hidden=true><ul class=mobile-nav-links><li><a href=/projects/>Projects</a></li><li><a href=/blog/>Blog</a></li><li><a href=/about/>About</a></li><li><a href=https://github.com/nixlim target=_blank rel="noopener noreferrer" aria-label=GitHub>GitHub</a></li></ul></div></nav><main id=content><div class=container><article class=blog-post><h1>Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions</h1><div class=post-meta-row><time datetime=2026-02-01>February 1, 2026</time>
<span class=text-muted>&#183;</span>
<span class=text-muted>7 min read</span>
<span class=text-muted>&#183;</span>
<a href=/tags/task-templating/ class=tag-pill>task-templating</a>
<a href=/tags/architecture/ class=tag-pill>architecture</a>
<a href=/tags/vibe-coding/ class=tag-pill>vibe-coding</a>
<a href=/tags/agents/ class=tag-pill>agents</a></div><div class=content><img src=/images/task_templating.png alt="Task Templating: structured task specifications for AI coding agents"><p>Tell an AI coding agent to &ldquo;implement search&rdquo; and it will. It&rsquo;ll pick a library you didn&rsquo;t want, create files in directories you didn&rsquo;t expect, and deliver something that technically works but spiritually misses the point. The agent wasn&rsquo;t wrong &ndash; you were vague, and vagueness is an invitation for assumptions. The agent made twelve of them. You agreed with seven.</p><p>That five-assumption gap is where rework lives.</p><h2 id=the-shape-of-the-problem>The shape of the problem</h2><p>Every natural language task description has holes. &ldquo;Add a CLI flag for export format&rdquo; leaves unanswered: which formats? What&rsquo;s the default? Where does output go &ndash; stdout or file? What happens when someone passes <code>--format xml</code> and you don&rsquo;t support XML? Does the output include colour codes or is it pipe-safe? These aren&rsquo;t edge cases. These are the actual specification, and you skipped all of it.</p><p>The conventional fix is &ldquo;write better prompts.&rdquo; This is the &ldquo;just be more careful&rdquo; school of engineering, and it works about as well as telling someone to &ldquo;just write fewer bugs.&rdquo; The problem isn&rsquo;t carelessness. The problem is that natural language doesn&rsquo;t have a compiler. There&rsquo;s no syntax error for an ambiguous instruction &ndash; the agent just picks an interpretation and keeps going.</p><p>So Opus and I built one. Not for me though ;) For Opus.</p><h2 id=two-tiers-of-refusal>Two tiers of refusal</h2><p>Task Templating defines a structured format where every task must declare its <code>TASK_ID</code>, <code>TASK_NAME</code>, <code>GOAL</code>, <code>INPUTS</code>, <code>OUTPUTS</code>, and <code>ACCEPTANCE</code> criteria. No optional hand-waving. The <code>taskval</code> CLI then runs two tiers of validation, because being thorough is the entire point.</p><p><strong>Tier 1</strong> is structural. JSON Schema checks that required fields exist, types are correct, <code>task_id</code> matches kebab-case, <code>priority</code> is one of <code>critical | high | medium | low</code>, and your inputs array isn&rsquo;t empty. Deterministic, zero-LLM, pass-or-fail. This catches the &ldquo;you forgot to fill in the form&rdquo; class of errors.</p><p><strong>Tier 2</strong> is where it gets interesting. Semantic validation runs only if Tier 1 passes, and it checks things JSON Schema can&rsquo;t express:</p><table><thead><tr><th>Rule</th><th>What it catches</th><th>Severity</th></tr></thead><tbody><tr><td>V2</td><td>Duplicate <code>task_id</code> across tasks</td><td>ERROR</td></tr><tr><td>V4</td><td>Dependency references that point at nothing</td><td>ERROR</td></tr><tr><td>V5</td><td>Circular dependencies (via Kahn&rsquo;s algorithm)</td><td>ERROR</td></tr><tr><td>V6</td><td>Goals containing &ldquo;try&rdquo;, &ldquo;explore&rdquo;, &ldquo;investigate&rdquo;</td><td>ERROR</td></tr><tr><td>V7</td><td>Acceptance criteria containing &ldquo;works correctly&rdquo;</td><td>WARNING</td></tr><tr><td>V9</td><td>Missing contextual fields without justification</td><td>WARNING</td></tr><tr><td>V10</td><td>Implementation tasks missing <code>files_scope</code></td><td>WARNING</td></tr></tbody></table><p>Rule V6 is the one that earns its keep. If your goal starts with &ldquo;try to add search functionality,&rdquo; you don&rsquo;t have a goal &ndash; you have a hope. The validator rejects it and tells you to rewrite it as a testable outcome. &ldquo;The <code>Search()</code> function returns ranked results from Weaviate hybrid search&rdquo; is a goal. &ldquo;Explore search options&rdquo; is a meeting agenda item.</p><p>V7 does the same for acceptance criteria. &ldquo;It works correctly&rdquo; is not a test case. &ldquo;Given input <code>'machine learning'</code> with <code>--limit 5</code>, the command returns at most 5 results, each with a Harvard citation&rdquo; is a test case. The difference matters when an agent is deciding whether it&rsquo;s done.</p><h2 id=the-feedback-loop>The feedback loop</h2><p>The pipeline is designed for agents to self-correct:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-fallback data-lang=fallback><span style=display:flex><span>flowchart TD
</span></span><span style=display:flex><span>    A[Natural language task] --&gt; B[Agent compiles to JSON]
</span></span><span style=display:flex><span>    B --&gt; C[taskval validates]
</span></span><span style=display:flex><span>    C --&gt; D{Pass?}
</span></span><span style=display:flex><span>    D -- Yes --&gt; E[Execute task]
</span></span><span style=display:flex><span>    D -- No --&gt; F[Agent reads structured errors]
</span></span><span style=display:flex><span>    F --&gt; G[Fix identified fields]
</span></span><span style=display:flex><span>    G --&gt; H{Attempt &lt; 3?}
</span></span><span style=display:flex><span>    H -- Yes --&gt; C
</span></span><span style=display:flex><span>    H -- No --&gt; I[Escalate to human]
</span></span></code></pre></div><p>Every error comes back with a rule ID, JSON path, problem description, and an actionable fix suggestion. The agent doesn&rsquo;t need to guess what went wrong &ndash; the validator tells it exactly which field failed, why, and what a correct version looks like.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>$ taskval --mode<span style=color:#f92672>=</span>task examples/invalid_task.json
</span></span><span style=display:flex><span>VALIDATION FAILED
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  1. <span style=color:#f92672>[</span>ERROR<span style=color:#f92672>]</span> Rule V6
</span></span><span style=display:flex><span>     Path:    tasks<span style=color:#f92672>[</span>0<span style=color:#f92672>]</span>.goal
</span></span><span style=display:flex><span>     Problem: Goal contains the forbidden word/phrase <span style=color:#e6db74>&#39;try&#39;</span>.
</span></span><span style=display:flex><span>     Fix:     Rewrite the goal as a concrete, testable outcome.
</span></span><span style=display:flex><span>              Instead of <span style=color:#e6db74>&#39;try ...&#39;</span>, describe what the system
</span></span><span style=display:flex><span>              does when the task is complete.
</span></span></code></pre></div><p>The agent reads this, rewrites the goal, and resubmits. No human in the loop. The conversation between the validator and the agent is the quality gate, and it runs in about 200 milliseconds.</p><h2 id=dags-not-wish-lists>DAGs, not wish lists</h2><p>Tasks have dependencies, and dependencies must form a Directed Acyclic Graph. The validator enforces this with Kahn&rsquo;s algorithm &ndash; a topological sort that detects cycles by counting in-degrees. If task A depends on task B which depends on task A, the validator tells you which tasks are involved and suggests breaking the cycle by decomposing one of them.</p><p>This matters because task graphs get created by agents too. You say &ldquo;build the search pipeline,&rdquo; the <code>/taskify</code> skill decomposes it into 10-15 tasks, and each task declares its dependencies. If the decomposition accidentally introduces a circular dependency &ndash; and LLMs do this more often than you&rsquo;d expect &ndash; the validator catches it before anyone tries to execute an impossible ordering.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;task_id&#34;</span>: <span style=color:#e6db74>&#34;weaviate-hybrid-search&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;depends_on&#34;</span>: [<span style=color:#e6db74>&#34;weaviate-client-setup&#34;</span>, <span style=color:#e6db74>&#34;embedding-pipeline&#34;</span>],
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;goal&#34;</span>: <span style=color:#e6db74>&#34;A Search() function queries Weaviate using hybrid search and returns ranked chunk results with scores.&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;acceptance&#34;</span>: [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Results are sorted by descending score&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Context cancellation mid-query returns context.Canceled error&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Empty collection returns empty list and nil error&#34;</span>
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>No &ldquo;it should work.&rdquo; No &ldquo;explore the options.&rdquo; Every field is a contract, and the contract is enforced before execution starts.</p><h2 id=from-validated-graph-to-tracked-issues>From validated graph to tracked issues</h2><p>Validation is necessary but not sufficient. Validated tasks need to become tracked work. The <code>--create-beads</code> flag bridges the gap &ndash; it takes a validated task graph and creates issues in the Beads (<code>bd</code>) issue tracker, preserving the dependency structure, mapping priorities and estimates, and attaching the full task specification as structured metadata.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>$ taskval --create-beads examples/valid_task_graph.json
</span></span><span style=display:flex><span>VALIDATION PASSED
</span></span><span style=display:flex><span>  Tasks validated: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>BEADS CREATION
</span></span><span style=display:flex><span>  Epic created: bd-a1b2 <span style=color:#e6db74>&#34;Task Graph: M1 - Core Infrastructure&#34;</span>
</span></span><span style=display:flex><span>  Task created: bd-c3d4 <span style=color:#e6db74>&#34;Implement discount calculation...&#34;</span> <span style=color:#f92672>(</span>calculate-discounted-total<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Task created: bd-e5f6 <span style=color:#e6db74>&#34;Add --format flag...&#34;</span> <span style=color:#f92672>(</span>cli-export-format-flag<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Task created: bd-g7h8 <span style=color:#e6db74>&#34;Implement hybrid BM25...&#34;</span> <span style=color:#f92672>(</span>weaviate-hybrid-search<span style=color:#f92672>)</span>
</span></span></code></pre></div><p>The pipeline runs in topological order &ndash; dependencies are created before the tasks that depend on them, so the issue tracker&rsquo;s dependency graph mirrors the task graph&rsquo;s DAG exactly. Priority mapping converts the spec&rsquo;s <code>critical | high | medium | low</code> to numeric values. Estimate mapping converts <code>trivial | small | medium | large</code> to minutes. Everything the agent needs to pick up the work and start executing is already in the issue.</p><p>A <code>--dry-run</code> flag previews the <code>bd</code> commands without executing them, for the appropriately paranoid.</p><h2 id=the-taskify-skill>The <code>/taskify</code> skill</h2><p>The whole pipeline collapses into a single Claude Code slash command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>/taskify docs/oauth-spec.md
</span></span></code></pre></div><p>The skill reads the spec, decomposes it into a structured task graph, validates it against the schema, self-corrects if validation fails (up to three attempts), and records the result as tracked Beads issues. Natural language in, validated and tracked work items out.</p><p>You can also pass inline descriptions:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>/taskify <span style=color:#e6db74>&#34;Add OAuth2 support with Google and GitHub providers&#34;</span>
</span></span></code></pre></div><p>The agent identifies distinct units of work (each targeting 30 minutes to 4 hours of effort), maps dependencies, assigns file scopes, writes testable acceptance criteria, and validates the lot. If a goal contains &ldquo;explore&rdquo; or an acceptance criterion says &ldquo;works correctly,&rdquo; the validator rejects it, the agent rewrites it, and the user never sees the vague version.</p><h2 id=the-actual-stack>The actual stack</h2><p>The whole thing is Go. One external dependency: <code>kaptinlin/jsonschema</code> for JSON Schema Draft 2020-12 validation. The Go standard library provides everything else &ndash; JSON parsing, regex for goal quality checks, embedded filesystem for bundling schemas. The <code>taskval</code> binary compiles to a single executable. No Docker. No database. No runtime dependencies.</p><p>The validator, the beads integration, and the CLI total about 1,500 lines of Go. Kahn&rsquo;s algorithm for cycle detection is 50 lines. The vague-phrase detector for acceptance criteria is a list of eight regex patterns. The entire semantic validation tier is a single file. Keeping the validation pipeline lightweight is the kind of constraint that prevents it from becoming the problem it&rsquo;s trying to solve.</p><h2 id=the-meta-point>The meta-point</h2><p>Every AI agent quality problem is, at its root, a specification problem. The agent didn&rsquo;t hallucinate &ndash; you under-specified. The agent didn&rsquo;t go rogue &ndash; it filled the gaps you left with reasonable-sounding assumptions that happened to be wrong. The fix isn&rsquo;t a better model. The fix is a better contract.</p><p>Task Templating is that contract, with a compiler that rejects the vague parts before they become code.</p></div><a href=/blog/ class=back-link>&larr; Back to Blog</a></article></div></main><footer class=site-footer><div class=footer-container><p class=footer-tagline>Because why not?</p><p class=footer-copyright>&copy; 2026 Foundry of Zero.
<a href=https://github.com/nixlim target=_blank rel="noopener noreferrer">GitHub</a></p><p class=footer-credit>Vibe-coded with <a href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a>. Because why not.</p></div></footer><script src=/js/nav.js defer></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("code.language-mermaid");if(t.length===0)return;t.forEach(function(e){const n=e.parentElement,t=document.createElement("div");t.className="mermaid",t.textContent=e.textContent,n.parentElement.replaceChild(t,n)});const e=document.createElement("script");e.src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js",e.onload=function(){mermaid.initialize({startOnLoad:!0,theme:"dark",themeVariables:{darkMode:!0,background:"#111111",primaryColor:"#1a3a1a",primaryTextColor:"#e0e0e0",primaryBorderColor:"#00ff41",secondaryColor:"#2a1a0a",secondaryTextColor:"#e0e0e0",secondaryBorderColor:"#b87333",tertiaryColor:"#1a1a1a",lineColor:"#00ff41",textColor:"#e0e0e0",mainBkg:"#1a3a1a",nodeBorder:"#00ff41",clusterBkg:"#111111",titleColor:"#00ff41",edgeLabelBackground:"#111111",nodeTextColor:"#e0e0e0"},flowchart:{htmlLabels:!0,curve:"basis"}}),mermaid.run()},document.head.appendChild(e)})</script></body></html>