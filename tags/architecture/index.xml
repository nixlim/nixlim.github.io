<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Architecture on Foundry of Zero</title><link>https://foundryofzero.ai/tags/architecture/</link><description>Recent content in Architecture on Foundry of Zero</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 01 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://foundryofzero.ai/tags/architecture/index.xml" rel="self" type="application/rss+xml"/><item><title>Optimising Quote Retrieval: How AQE Finds Better Needles in Academic Haystacks</title><link>https://foundryofzero.ai/blog/batched-scoring-aqe/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/batched-scoring-aqe/</guid><description>&lt;img src="https://foundryofzero.ai/images/getting_better_quotes.png" alt="Getting better quotes from academic papers"&gt;
&lt;p&gt;Academic Quote Extractor has a deceptively simple job: you give it a research topic, it gives you real quotes from real papers with real citations. Under the hood, it&amp;rsquo;s a hybrid RAG pipeline &amp;ndash; Weaviate for retrieval, Claude for relevance scoring, SQLite for ground truth. It worked. The quotes came back correct, the citations were verifiable, and nobody was hallucinating references.&lt;/p&gt;
&lt;p&gt;But &amp;ldquo;correct&amp;rdquo; and &amp;ldquo;comprehensive&amp;rdquo; are different things. The pipeline was leaving good quotes on the table, and it took an audit of the entire search flow to understand why.&lt;/p&gt;</description></item><item><title>Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions</title><link>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</guid><description>&lt;img src="https://foundryofzero.ai/images/task_templating.png" alt="Task Templating: structured task specifications for AI coding agents"&gt;
&lt;p&gt;Tell an AI coding agent to &amp;ldquo;implement search&amp;rdquo; and it will. It&amp;rsquo;ll pick a library you didn&amp;rsquo;t want, create files in directories you didn&amp;rsquo;t expect, and deliver something that technically works but spiritually misses the point. The agent wasn&amp;rsquo;t wrong &amp;ndash; you were vague, and vagueness is an invitation for assumptions. The agent made twelve of them. You agreed with seven.&lt;/p&gt;
&lt;p&gt;That five-assumption gap is where rework lives.&lt;/p&gt;</description></item></channel></rss>