<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bdd on Foundry of Zero</title><link>https://foundryofzero.ai/tags/bdd/</link><description>Recent content in Bdd on Foundry of Zero</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 04 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://foundryofzero.ai/tags/bdd/index.xml" rel="self" type="application/rss+xml"/><item><title>Plan-Spec: Teaching Agents to Think Before They Code</title><link>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</link><pubDate>Wed, 04 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</guid><description>&lt;img src="https://foundryofzero.ai/images/plan-spec.png" alt="Plan-Spec: structured specification pipeline for AI coding agents"&gt;
&lt;p&gt;A good specification answers four questions: what are we building, how do we know it works, what happens when it doesn&amp;rsquo;t, and where does each requirement trace to? Most AI-generated plans answer the first question enthusiastically and hand-wave the other three.&lt;/p&gt;
&lt;p&gt;The problem isn&amp;rsquo;t that the agent can&amp;rsquo;t think. The problem is that nobody told it how to think &lt;em&gt;systematically&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This matters because specifications are contracts. When an agent builds from a spec that says &amp;ldquo;user can reset their password&amp;rdquo; with no acceptance criteria, no boundary conditions, and no test plan, the agent fills the gaps itself.&lt;/p&gt;</description></item></channel></rss>