<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Agents on Foundry of Zero</title><link>https://foundryofzero.ai/tags/agents/</link><description>Recent content in Agents on Foundry of Zero</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 04 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://foundryofzero.ai/tags/agents/index.xml" rel="self" type="application/rss+xml"/><item><title>Plan-Spec: Teaching Agents to Think Before They Code</title><link>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</link><pubDate>Wed, 04 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</guid><description>&lt;img src="https://foundryofzero.ai/images/plan-spec.png" alt="Plan-Spec: structured specification pipeline for AI coding agents"&gt;
&lt;p&gt;A good specification answers four questions: what are we building, how do we know it works, what happens when it doesn&amp;rsquo;t, and where does each requirement trace to? Most AI-generated plans answer the first question enthusiastically and hand-wave the other three.&lt;/p&gt;
&lt;p&gt;The problem isn&amp;rsquo;t that the agent can&amp;rsquo;t think. The problem is that nobody told it how to think &lt;em&gt;systematically&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This matters because specifications are contracts. When an agent builds from a spec that says &amp;ldquo;user can reset their password&amp;rdquo; with no acceptance criteria, no boundary conditions, and no test plan, the agent fills the gaps itself.&lt;/p&gt;</description></item><item><title>Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions</title><link>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</guid><description>&lt;img src="https://foundryofzero.ai/images/task_templating.png" alt="Task Templating: structured task specifications for AI coding agents"&gt;
&lt;p&gt;Tell an AI coding agent to &amp;ldquo;implement search&amp;rdquo; and it will. It&amp;rsquo;ll pick a library you didn&amp;rsquo;t want, create files in directories you didn&amp;rsquo;t expect, and deliver something that technically works but spiritually misses the point. The agent wasn&amp;rsquo;t wrong &amp;ndash; you were vague, and vagueness is an invitation for assumptions. The agent made twelve of them. You agreed with seven.&lt;/p&gt;
&lt;p&gt;That five-assumption gap is where rework lives.&lt;/p&gt;</description></item></channel></rss>