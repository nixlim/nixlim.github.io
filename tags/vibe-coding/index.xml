<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vibe-Coding on Foundry of Zero</title><link>https://foundryofzero.ai/tags/vibe-coding/</link><description>Recent content in Vibe-Coding on Foundry of Zero</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 04 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://foundryofzero.ai/tags/vibe-coding/index.xml" rel="self" type="application/rss+xml"/><item><title>Plan-Spec: Teaching Agents to Think Before They Code</title><link>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</link><pubDate>Wed, 04 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</guid><description>&lt;img src="https://foundryofzero.ai/images/plan-spec.png" alt="Plan-Spec: structured specification pipeline for AI coding agents"&gt;
&lt;p&gt;A good specification answers four questions: what are we building, how do we know it works, what happens when it doesn&amp;rsquo;t, and where does each requirement trace to? Most AI-generated plans answer the first question enthusiastically and hand-wave the other three.&lt;/p&gt;
&lt;p&gt;The problem isn&amp;rsquo;t that the agent can&amp;rsquo;t think. The problem is that nobody told it how to think &lt;em&gt;systematically&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This matters because specifications are contracts. When an agent builds from a spec that says &amp;ldquo;user can reset their password&amp;rdquo; with no acceptance criteria, no boundary conditions, and no test plan, the agent fills the gaps itself.&lt;/p&gt;</description></item><item><title>Optimising Quote Retrieval: How AQE Finds Better Needles in Academic Haystacks</title><link>https://foundryofzero.ai/blog/batched-scoring-aqe/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/batched-scoring-aqe/</guid><description>&lt;img src="https://foundryofzero.ai/images/getting_better_quotes.png" alt="Getting better quotes from academic papers"&gt;
&lt;p&gt;Academic Quote Extractor has a deceptively simple job: you give it a research topic, it gives you real quotes from real papers with real citations. Under the hood, it&amp;rsquo;s a hybrid RAG pipeline &amp;ndash; Weaviate for retrieval, Claude for relevance scoring, SQLite for ground truth. It worked. The quotes came back correct, the citations were verifiable, and nobody was hallucinating references.&lt;/p&gt;
&lt;p&gt;But &amp;ldquo;correct&amp;rdquo; and &amp;ldquo;comprehensive&amp;rdquo; are different things. The pipeline was leaving good quotes on the table, and it took an audit of the entire search flow to understand why.&lt;/p&gt;</description></item><item><title>Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions</title><link>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</guid><description>&lt;img src="https://foundryofzero.ai/images/task_templating.png" alt="Task Templating: structured task specifications for AI coding agents"&gt;
&lt;p&gt;Tell an AI coding agent to &amp;ldquo;implement search&amp;rdquo; and it will. It&amp;rsquo;ll pick a library you didn&amp;rsquo;t want, create files in directories you didn&amp;rsquo;t expect, and deliver something that technically works but spiritually misses the point. The agent wasn&amp;rsquo;t wrong &amp;ndash; you were vague, and vagueness is an invitation for assumptions. The agent made twelve of them. You agreed with seven.&lt;/p&gt;
&lt;p&gt;That five-assumption gap is where rework lives.&lt;/p&gt;</description></item><item><title>Hello, World</title><link>https://foundryofzero.ai/blog/hello-world/</link><pubDate>Sat, 31 Jan 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/hello-world/</guid><description>&lt;p&gt;This is Foundry of Zero. It exists because it can. Because there&amp;rsquo;s no law of physics that says it shouldn&amp;rsquo;t, and because the tokens were available to make it happen. If that reasoning sounds insufficient, consider that most of the universe exists for less compelling reasons.&lt;/p&gt;
&lt;h2 id="what-happens-here"&gt;What happens here&lt;/h2&gt;
&lt;p&gt;Things get built. Not because the world needs another framework or another SaaS dashboard, but because certain problems are interesting enough that leaving them unsolved feels like a personal insult to the laws of thermodynamics. Multi-agent orchestration. Zero-hallucination academic research tools. Validators that reject vague task descriptions with the cold precision of a compiler. The kind of software that makes you ask &amp;ldquo;wait, that works?&amp;rdquo; and the answer is yes, it does, actually.&lt;/p&gt;</description></item></channel></rss>