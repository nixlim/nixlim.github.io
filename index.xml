<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Foundry of Zero</title><link>https://foundryofzero.ai/</link><description>Recent content on Foundry of Zero</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 04 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://foundryofzero.ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Hive</title><link>https://foundryofzero.ai/projects/hive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/projects/hive/</guid><description>&lt;p&gt;The premise is absurd and therefore worth trying: take multiple Claude Code agents, give them distinct roles &amp;ndash; architect, engineer, reviewer &amp;ndash; and make them collaborate on real software tasks like a dysfunctional but surprisingly productive team.&lt;/p&gt;
&lt;p&gt;Hive throws out the assumption that AI coding means one agent, one task, one context window. Instead, there&amp;rsquo;s a supervisor process that breaks objectives into pieces, assigns them to a pool of agents, and lets each one work in its own isolated git worktree. Nobody steps on anyone&amp;rsquo;s toes. Nobody shares a context window. They just&amp;hellip; build things in parallel, and somehow it works.&lt;/p&gt;</description></item><item><title>Academic Quote Extractor</title><link>https://foundryofzero.ai/projects/academic-quote-extractor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/projects/academic-quote-extractor/</guid><description>&lt;p&gt;Here&amp;rsquo;s a thing that shouldn&amp;rsquo;t need to exist but does: a CLI that reads your academic papers, finds the quotes you actually need, and spits out properly formatted Harvard citations. You ask a research question, it gives you real quotes with real page numbers from real sources. No hallucinated references. No fabricated citations. No &amp;ldquo;this paper by et al. (2024) that definitely doesn&amp;rsquo;t exist.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The zero-hallucination guarantee is the whole point. The LLM never generates or paraphrases quotes &amp;ndash; it only scores relevance of passages that were already retrieved verbatim from SQLite. Every single citation traces back to exact source text. This exists because the most dangerous thing an LLM can do in academia is make up a reference that sounds plausible, and someone decided that was a solvable problem rather than an acceptable risk.&lt;/p&gt;</description></item><item><title>OpenCode Beads Plugin</title><link>https://foundryofzero.ai/projects/opencode-beads-plugin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/projects/opencode-beads-plugin/</guid><description>&lt;p&gt;The problem is dumb and the solution is elegant: AI coding agents have no memory of your project&amp;rsquo;s issues, tasks, or priorities unless you manually paste them in every single time. That&amp;rsquo;s the kind of tedious, repetitive work that computers were literally invented to eliminate. So this plugin eliminates it.&lt;/p&gt;
&lt;p&gt;It hooks into three moments of an OpenCode session. When a session starts, it runs &lt;code&gt;bd prime&lt;/code&gt; and injects the full project context &amp;ndash; open issues, priorities, workflow conventions &amp;ndash; straight into the agent&amp;rsquo;s prompt. When context gets compacted, it re-injects so nothing gets lost. When the session goes idle, it syncs issue state back to git. The agent just &lt;em&gt;knows&lt;/em&gt; what needs doing without you having to explain it again.&lt;/p&gt;</description></item><item><title>Task Templating</title><link>https://foundryofzero.ai/projects/task-templating/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/projects/task-templating/</guid><description>&lt;p&gt;Tell an AI agent to &amp;ldquo;build the thing&amp;rdquo; and it will happily build &lt;em&gt;a&lt;/em&gt; thing. Whether it&amp;rsquo;s &lt;em&gt;your&lt;/em&gt; thing depends entirely on how many assumptions it made to fill the gaps in your vague description. The answer is usually &amp;ldquo;too many.&amp;rdquo; Task Templating exists because someone got tired of the rework loop and decided to make ambiguity structurally impossible.&lt;/p&gt;
&lt;p&gt;The format forces completeness. Every task needs a &lt;code&gt;TASK_ID&lt;/code&gt;, &lt;code&gt;TASK_NAME&lt;/code&gt;, &lt;code&gt;GOAL&lt;/code&gt;, &lt;code&gt;INPUTS&lt;/code&gt;, &lt;code&gt;OUTPUTS&lt;/code&gt;, and &lt;code&gt;ACCEPTANCE&lt;/code&gt; criteria. No optional hand-waving. You also specify &lt;code&gt;DEPENDS_ON&lt;/code&gt;, &lt;code&gt;CONSTRAINTS&lt;/code&gt;, and &lt;code&gt;FILES_SCOPE&lt;/code&gt; because context matters and &amp;ldquo;just figure it out&amp;rdquo; is not architecture. If a field is empty, the task isn&amp;rsquo;t ready, and the validator will tell you so in terms that leave no room for negotiation.&lt;/p&gt;</description></item><item><title>Plan-Spec: Teaching Agents to Think Before They Code</title><link>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</link><pubDate>Wed, 04 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/plan-spec-teaching-agents-to-think-before-they-code/</guid><description>&lt;img src="https://foundryofzero.ai/images/plan-spec.png" alt="Plan-Spec: structured specification pipeline for AI coding agents"&gt;
&lt;p&gt;A good specification answers four questions: what are we building, how do we know it works, what happens when it doesn&amp;rsquo;t, and where does each requirement trace to? Most AI-generated plans answer the first question enthusiastically and hand-wave the other three.&lt;/p&gt;
&lt;p&gt;The problem isn&amp;rsquo;t that the agent can&amp;rsquo;t think. The problem is that nobody told it how to think &lt;em&gt;systematically&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This matters because specifications are contracts. When an agent builds from a spec that says &amp;ldquo;user can reset their password&amp;rdquo; with no acceptance criteria, no boundary conditions, and no test plan, the agent fills the gaps itself.&lt;/p&gt;</description></item><item><title>Optimising Quote Retrieval: How AQE Finds Better Needles in Academic Haystacks</title><link>https://foundryofzero.ai/blog/batched-scoring-aqe/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/batched-scoring-aqe/</guid><description>&lt;img src="https://foundryofzero.ai/images/getting_better_quotes.png" alt="Getting better quotes from academic papers"&gt;
&lt;p&gt;Academic Quote Extractor has a deceptively simple job: you give it a research topic, it gives you real quotes from real papers with real citations. Under the hood, it&amp;rsquo;s a hybrid RAG pipeline &amp;ndash; Weaviate for retrieval, Claude for relevance scoring, SQLite for ground truth. It worked. The quotes came back correct, the citations were verifiable, and nobody was hallucinating references.&lt;/p&gt;
&lt;p&gt;But &amp;ldquo;correct&amp;rdquo; and &amp;ldquo;comprehensive&amp;rdquo; are different things. The pipeline was leaving good quotes on the table, and it took an audit of the entire search flow to understand why.&lt;/p&gt;</description></item><item><title>Taskify Skill and TaskVal CLI: Teaching Agents to Refuse Vague Instructions</title><link>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</link><pubDate>Sun, 01 Feb 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/taskify-teaching-agents-to-refuse-vague-instructions/</guid><description>&lt;img src="https://foundryofzero.ai/images/task_templating.png" alt="Task Templating: structured task specifications for AI coding agents"&gt;
&lt;p&gt;Tell an AI coding agent to &amp;ldquo;implement search&amp;rdquo; and it will. It&amp;rsquo;ll pick a library you didn&amp;rsquo;t want, create files in directories you didn&amp;rsquo;t expect, and deliver something that technically works but spiritually misses the point. The agent wasn&amp;rsquo;t wrong &amp;ndash; you were vague, and vagueness is an invitation for assumptions. The agent made twelve of them. You agreed with seven.&lt;/p&gt;
&lt;p&gt;That five-assumption gap is where rework lives.&lt;/p&gt;</description></item><item><title>Hello, World</title><link>https://foundryofzero.ai/blog/hello-world/</link><pubDate>Sat, 31 Jan 2026 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/blog/hello-world/</guid><description>&lt;p&gt;This is Foundry of Zero. It exists because it can. Because there&amp;rsquo;s no law of physics that says it shouldn&amp;rsquo;t, and because the tokens were available to make it happen. If that reasoning sounds insufficient, consider that most of the universe exists for less compelling reasons.&lt;/p&gt;
&lt;h2 id="what-happens-here"&gt;What happens here&lt;/h2&gt;
&lt;p&gt;Things get built. Not because the world needs another framework or another SaaS dashboard, but because certain problems are interesting enough that leaving them unsolved feels like a personal insult to the laws of thermodynamics. Multi-agent orchestration. Zero-hallucination academic research tools. Validators that reject vague task descriptions with the cold precision of a compiler. The kind of software that makes you ask &amp;ldquo;wait, that works?&amp;rdquo; and the answer is yes, it does, actually.&lt;/p&gt;</description></item><item><title>About</title><link>https://foundryofzero.ai/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://foundryofzero.ai/about/</guid><description>&lt;img src="https://foundryofzero.ai/images/inventor.png" alt="The Inventor - steampunk goblin illustration"&gt;
&lt;h2 id="the-foundry"&gt;The Foundry&lt;/h2&gt;
&lt;p&gt;Foundry of Zero is where things get built because they can be. Because there are no laws of physics preventing them to be built and because tokens are available to do so. Foundry of Zero is a testament to complete and full adoption of vibe coding as a philosophy, to the chagrin of the naysayers, the doubters, the hubriant.&lt;/p&gt;
&lt;p&gt;The Foundry of Zero is a garage where the universe accidentally left its reality settings unlocked. A place where things exist not because they should, but because no one remembered to toggle off the &amp;ldquo;Why Not?&amp;rdquo; flag in the laws of physics config file.&lt;/p&gt;</description></item></channel></rss>